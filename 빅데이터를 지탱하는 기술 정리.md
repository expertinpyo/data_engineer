# 빅데이터를 지탱하는 기술 정리

저자 : 니시다 케이스케



### CH 1



빅데이터 취급이 어려운 이유

1. 데이터의 분석 방법을 모름
2. 데이터 처리에 수고와 시간이 소요



빅데이터 대표 기술 : Hadoop and NoSQL

- Hadoop 
  - 다수의 컴퓨터에서 대량의 데이터 처리하기 위한 시스템
- NoSQL
  - 빈번한 읽기/쓰기 및 분산 처리가 강점



이 둘을 조합함으로써 NoSQL 데이터베이스에 기록 + Hadoop으로 분산처리하기



데이터 웨어하우스 => 이전의 데이터 분석 방법

지금도 여전히 

가속도적으로 늘어나는 데이터 처리는 Hadoop으로, 

비교적 작거나 중요한 데이터는 데이터 웨어하우스에 넣는 식으로 사용



빅데이터와 스몰 데이터 차이

- 모두 그냥 데이터임. 본질적인 차이없음
- 대량의 데이터의 경우 과거라면 버릴 수 밖에 없었던 데이터였지만, 빅데이터 시대가 도래하고 이들을 핸들링할 수 있게 된 것일 뿐.



데이터 디스커버리

=> 대화형으로 데이터를 시각화하여 가치 있는 정보를 찾으려고 하는 프로세스, 셀프 서비스용 BI라고 불리움

=> 대표적인 것 :Tableau Public



빅데이터 기술이 기존의 데이터 웨어하우스와 다른 점

=> 다수의 분산 시스템을 조합하여 확장성이 뛰어난 데이터 처리 구조를 만든다는 점.



데이터 파이프라인(Data PipeLine)

=> 차례대로 전달해가는 데이터로 구성된 시스템



데이터 전송(Data Transfer)

- 벌크 형
  - 이미 어딘가에 존재하는 데이터를 처리해 추출하는 방법
  - 데이터베이스와 파일 서버 등에서 정기적으로 데이터를 수집하는데 사용
- 스트리밍 형
  - 차례차례로 생성되는 데이터를 끊임없이 계속해서 보내는 방법
  - 모바일 앱, 임베디드 장비 등에서 사용



요즘 추세는 스트리밍 형 방법임.

스트리밍 형으로 받은 데이터를 실시간으로 처리하는 것 => 스트림 처리(stream processing)

장기적 데이터 분석을 위해서는 배치 처리(batch processing)이 선호됨



워크플로(work flow)

=> 전체 데이터 파이프라인의 동작 관리를 위한 것 / 매일 정해진 시간에 배치 처리를 스케쥴대로 실행함. 오류 발생 시 관리자에게 통지하는 목적으로 사용됨



데이터 웨어하우스와 데이터 마트 - 데이터 파이프라인의 기본형

- 데이터 웨어하우스
  - 대량의 데이터를 장기 보존하는 것에 최적화
  - 소량의 데이터를 자주 읽고 쓰는 것에 부적합
  - ETL 프로세스 : 데이터 소스(RDB, 로그 등을 저장하는 파일 서버)에서 Raw Data Extract, 가공(Transform) 후 데이터 웨어하우스에 저장(Load)

- 데이터 마트
  - 데이터 웨어하우스는 주로 중요한 업무를 다루는 경우가 많으므로 함부로 사용해 과부하 주는 행위를 막아야함
  - 데이터 웨어하우스에서 필요한 데이터들만 추출한 후 데이터 마트를 구축
  - BI도구와 조합시키는 형태, 데이터 시각화에 사용됨



데이터 레이크(Data Lake)

=> 모든 데이터를 원래 형태로 축적 후 나중에 그것을 필요에 따라 가공하는 구조

​	 주로 임의의 데이터를 저장할 수 있는 분산 스토리지가 데이터 레이크로 이용된다.



데이터 레이크

- 단순한 Storage. 그것만으로는 데이터 가공 불가능
- 따라서 MapReduce 등의 분산 데이터 처리 기술을 사용해 이를 가공 및 분석할 수 있음

 

애드 혹 분석(ad hoc analysis)

=> 수작업으로 데이터를 집계하는 것

​	 데이터 마트를 만들지 않고 데이터 레이크, 데이터 웨어하우스에 직접 연결하는 경우 많음



시각화에 BI 도구를 이용할 경우 집계속도 향상을 위해 데이터 마트는 필수적임





데이터 분석

- 확증적 데이터 분석(confirmatory data analysis)
  - 통계학적 모델링에 의한 데이터 분석
- 탐색적 데이터 분석(exploratory data analysis)
  - 데이터 시각화 후 분석





### CH 2



트랜젝션 테이블(Transaction Table) : 행 방향으로만 데이터가 증가하고, 열 방향으로는 변화 없는 테이블, 종방향 테이블

크로스 테이블(Cross Table) : 행과 열이 교차하는 부분에 숫자 데이터가 들어가는 테이블. 횡방향 테이블

트랜젝션 테이블 => 크로스 테이블로 변환하는 과정을 ""크로스 집계(corss tabulation)""이라고 함.

위와 같은 기능을 하는 것이 피벗 테이블(pivot table)



종 => 횡 : 피벗

횡 => 종 : 언피벗



데이터 집계 => 데이터 마트 => 시각화

데이터 마트의 크기에 따라 시스템 구성이 결정된다.



데이터베이스의 시간 지연 줄이기

1. 원 데이터는 용량적인 제약이 적으므로 대량 데이터 처리가 가능한 데이터 레이크 & 데이터 웨어하우스에 저장(데이터 집계, 수분~수시간 소요)
2. 원하는 데이터를 추출하여 데이터 마트를 구축 후 항상 초 단위의 응답을 얻을 수 있도록 함.(크로스 집계 사용, 수 초 소요)



데이터 처리의 응답이 빠르다 = 대기시간(Latency)이 적다 or 지연이 적다

데이터 마트를 만들 때는 가급적 지연이 적은 데이터베이스가 있어야 함.



지연 적은 데이터베이스 만드는 법

1. 모든 데이터를 메모리에 올리는 것

   - 데이터 용량 규모가 N 기가바이트면 감당 가능할 듯.

   - 하지만 RDB(관계형 데이터베이스)는 메모리가 부족하면 성능 저하 극심함.

2. 압축과 분산에 의해 지연 줄이기(MPP 기술)

   - 데이터를 가능한 작게 압축하고 그 것을 여러 디스크에 분산함으로써 데이터의 로드에 따른 지연을 줄임
   - 분산된 데이터를 읽어들이기 위해 멀티 코어를 활용하면서 디스크 I/O를 병렬처리 하는 것이 효과적
   - 이를 MPP(Massive parallel processing, 대규모 병렬처리)라고 불리움



일반적인 업무에 사용되는 데이터베이스 => 행 지향 데이터베이스, 레코드 단위의 읽고 쓰기 가능

BUT 데이터 분석에 사용되는 데이터베이스 => 열 지향 데이터베이스, 칼럼 단위 집계에 최적화



처리량과 지연시간

- 데이터 웨어하우스, 데이터 레이크 : 대량 데이터 처리를 위해 처리량 우선
- 데이터 마트 : 지연 시간 단축이 우선 순위 => 충분한 메모리 준비 or 디스크 I/O 절감 필수



행 지향 vs 열 지향 데이터베이스

- 행 지향

  - 테이블 각 행을 하나의 덩어리로 디스크에 저장
  - 새 레코드 추가 시 파일의 끝에 데이터 씀 => 약간 스택 느낌
  - 데이터 추가를 효율적으로 할 수 있음

  - 데이터 검색 고속화를 위해 index 존재

- 열 지향

  - 데이터를 미리 칼럼 단위로 정리해 둠
  - 필요한 칼럼만을 로드할 수 있어 I/O 줄이기 가능
  - 데이터 압축 효율도 행 지향 대비 10배 정도 우수



쿼리 지연을 위한 또 다른 방법 - MPP 아키텍쳐에 의한 데이터 처리 병렬화

- 행 지향 DB에서 하나의 쿼리 - 하나의 스레드에서 실행

  - 많은 쿼리 동시 실행 => 여러개의 cpu 코어 활용 가능 BUT 개별 쿼리가 분산처리 되는 것은 아님

- 열 지향 DB => 대량 데이터를 읽으므로 1번의 쿼리 실행 시간 길어짐 + 압축된 데이터의 전개 등으로 CPU 리소스 많이 필요

  => 멀티코어를 통한 고속화 필요

- MPP는 하나의 쿼리를 다수의 작은 테스크로 분해, 이를 가능한 한 병렬로 실행함.



결론 : 수억 레코드를 초과하는 데이터 마트의 지연을 작게 유지하기 위해서는 데이터를 "열 지향 스토리지" 형식으로 저장해야함.



데이터 시각화 위한 도구

1. Jupyter Notebook
   - 에드 훅 분석에 특화
   - matplotlib을  통한 시각화 가능
   - 간이적인 워크플로우 가능

2. 대시보드 도구
   - 정기적으로 쿼리를 실행해 보고서 작성 등에 활용
   - BI 대비 새로운 그래프를 쉽게 추가하는 것이 중시된다.
   - 워크플로우 가능, 최소 하루 한번 자동 갱신 or 실시간 업데이트 가능
   - Redash(sql 기반), Superset(마우스 조작 기반, 대화형), Kibana(Elasticsearch 프론트엔드 기반) 등 존재

3. BI 도구
   - n 개월 단위의 장기 데이터 추이의 시각화 or 집계 조건을 세부적으로 바꿀 수 있음
   - 이미 있는 데이터 가져오기 + 데이터 분석을 쉽게하기 위해 데이터 가공하는 일 존재
   - 알고싶은 것이 늘어날 때 마다 데이터 마트에 테이블을 만들고 거기에서 파생된 다수의 대시보드가 생겨나는 것이 시각화 과정



OLAP(Online Analytical Processing)

- 데이터 집계를 효율화하는 방법 중 하나
- 다차원 모델의 데이터 구조를 MDX(multidimensional expressions) 등의 쿼리 언어로 집계함
- 데이터 분석을 위해 만들어진 다차원 데이터 => OLAP 큐브, 이 것을 크로스 집계하는 구조 => OLAP



MPP 등장 이전 사용되었으나, 요새는 BI 도구 + MPP 데이터 베이스를 조합한 크로스 집계가 증가하는 추세

- MPP DB에는 다차원 모델 개념이 없고, 비정규화 테이블이 이를 대체함.

 



in Table

트랜잭션(transaction) : 시간과 함께 생성되는 데이터를 기록한 것, 변화 X

마스터(master) : 트랜젝션에서 참고되는 각종 정보, 변화 O



in DataWarehouse

팩트 테이블(Fact Table) : 트랜잭션처럼 사실이 기록된 것

디멘전 테이블(Dimension Table) : 거기에서 참고되는 마스터 데이터 등을 담고있는 것



스타 스키마(Start Schema)

데이터 마트를 만들 때 팩트 테이블을 중심으로 여러 디멘젼 테이블이 결합 => 스타 스키마



비정규화(denormalization)

정규화에 의해 분해된 테이블을 최대한 결합하여 하나의 테이블로 정리하려고 하는 것



데이터 마켓에서 스타 스키마가 사용되는 이유

1. 단순한 구조 때문에 이해 쉽고 데이터 분석 쉽게 가능

2. 성능 상의 이유

​	=> 팩트 테이블을 최대한 작게, 나머지는 디멘젼 테이블로 옮기기 => 쿼리 지연 감소에 효과적

​	=> 하지만, 이 문제는 열 지향 스토리지에 의해 해결된다.



데이터 마트에 정규화 테이블은 필요없음



데이터 마트에 스타 스키마 사용된 것은 과거 이야기임

(데이터 웨어하우스의 테이블 구조로는 스타 스키마 우수함)



비정규화 테이블 = 스타 스키마에서 좀 더 비정규화를 진행해 모든 테이블을 결합한 팩트 테이블

데이터 마트는 이 비정규화 테이블로 하는 것이 가장 단순, 효율적임



다차원 모델 : BI 도구의 기본 데이터 모델. 테이블, 칼럼의 집합을 쉽게 정리해 이름 붙인 것

=> 칼럼을 디멘전(숫자데이터, 그 집계 방법을 정의하는 것) / 측정값(크로스 집계에 있어 행과 열을 이용하는 것)으로 분리함





