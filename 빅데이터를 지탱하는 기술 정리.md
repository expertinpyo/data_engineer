# 빅데이터를 지탱하는 기술 정리

저자 : 니시다 케이스케



### CH 1



빅데이터 취급이 어려운 이유

1. 데이터의 분석 방법을 모름
2. 데이터 처리에 수고와 시간이 소요



빅데이터 대표 기술 : Hadoop and NoSQL

- Hadoop 
  - 다수의 컴퓨터에서 대량의 데이터 처리하기 위한 시스템
- NoSQL
  - 빈번한 읽기/쓰기 및 분산 처리가 강점



이 둘을 조합함으로써 NoSQL 데이터베이스에 기록 + Hadoop으로 분산처리하기



데이터 웨어하우스 => 이전의 데이터 분석 방법

지금도 여전히 

가속도적으로 늘어나는 데이터 처리는 Hadoop으로, 

비교적 작거나 중요한 데이터는 데이터 웨어하우스에 넣는 식으로 사용



빅데이터와 스몰 데이터 차이

- 모두 그냥 데이터임. 본질적인 차이없음
- 대량의 데이터의 경우 과거라면 버릴 수 밖에 없었던 데이터였지만, 빅데이터 시대가 도래하고 이들을 핸들링할 수 있게 된 것일 뿐.



데이터 디스커버리

=> 대화형으로 데이터를 시각화하여 가치 있는 정보를 찾으려고 하는 프로세스, 셀프 서비스용 BI라고 불리움

=> 대표적인 것 :Tableau Public



빅데이터 기술이 기존의 데이터 웨어하우스와 다른 점

=> 다수의 **분산 시스템**을 조합하여 확장성이 뛰어난 데이터 처리 구조를 만든다는 점.



데이터 파이프라인(Data PipeLine)

=> 차례대로 전달해가는 데이터로 구성된 시스템



데이터 전송(Data Transfer)

- 벌크 형
  - 이미 어딘가에 존재하는 데이터를 처리해 추출하는 방법
  - 데이터베이스와 파일 서버 등에서 정기적으로 데이터를 수집하는데 사용
- 스트리밍 형
  - 차례차례로 생성되는 데이터를 끊임없이 계속해서 보내는 방법
  - 모바일 앱, 임베디드 장비 등에서 사용



요즘 추세는 스트리밍 형 방법임.

스트리밍 형으로 받은 데이터를 실시간으로 처리하는 것 => 스트림 처리(stream processing)

장기적 데이터 분석을 위해서는 배치 처리(batch processing)이 선호됨



워크플로(work flow)

=> 전체 데이터 파이프라인의 동작 관리를 위한 것 / 매일 정해진 시간에 배치 처리를 스케쥴대로 실행함. 오류 발생 시 관리자에게 통지하는 목적으로 사용됨



데이터 웨어하우스와 데이터 마트 - 데이터 파이프라인의 기본형

- 데이터 웨어하우스
  - 대량의 데이터를 장기 보존하는 것에 최적화
  - 소량의 데이터를 자주 읽고 쓰는 것에 부적합
  - ETL 프로세스 : 데이터 소스(RDB, 로그 등을 저장하는 파일 서버)에서 Raw Data Extract, 가공(Transform) 후 데이터 웨어하우스에 저장(Load)

- 데이터 마트
  - 데이터 웨어하우스는 주로 중요한 업무를 다루는 경우가 많으므로 함부로 사용해 과부하 주는 행위를 막아야함
  - 데이터 웨어하우스에서 필요한 데이터들만 추출한 후 데이터 마트를 구축
  - BI도구와 조합시키는 형태, 데이터 시각화에 사용됨



데이터 레이크(Data Lake)

=> 모든 데이터를 원래 형태로 축적 후 나중에 그것을 필요에 따라 가공하는 구조

​	 주로 임의의 데이터를 저장할 수 있는 분산 스토리지가 데이터 레이크로 이용된다.



데이터 레이크

- 단순한 Storage. 그것만으로는 데이터 가공 불가능
- 따라서 MapReduce 등의 분산 데이터 처리 기술을 사용해 이를 가공 및 분석할 수 있음

 

애드 혹 분석(ad hoc analysis)

=> 수작업으로 데이터를 집계하는 것

​	 데이터 마트를 만들지 않고 데이터 레이크, 데이터 웨어하우스에 직접 연결하는 경우 많음



시각화에 BI 도구를 이용할 경우 집계속도 향상을 위해 데이터 마트는 필수적임





데이터 분석

- 확증적 데이터 분석(confirmatory data analysis)
  - 통계학적 모델링에 의한 데이터 분석
- 탐색적 데이터 분석(exploratory data analysis)
  - 데이터 시각화 후 분석





### CH 2



트랜젝션 테이블(Transaction Table) : 행 방향으로만 데이터가 증가하고, 열 방향으로는 변화 없는 테이블, 종방향 테이블

크로스 테이블(Cross Table) : 행과 열이 교차하는 부분에 숫자 데이터가 들어가는 테이블. 횡방향 테이블

트랜젝션 테이블 => 크로스 테이블로 변환하는 과정을 ""크로스 집계(cross tabulation)""이라고 함.

위와 같은 기능을 하는 것이 피벗 테이블(pivot table)



종 => 횡 : 피벗

횡 => 종 : 언피벗



데이터 집계 => 데이터 마트 => 시각화

데이터 마트의 크기에 따라 시스템 구성이 결정된다.



데이터베이스의 시간 지연 줄이기

1. 원 데이터는 용량적인 제약이 적으므로 대량 데이터 처리가 가능한 데이터 레이크 & 데이터 웨어하우스에 저장(데이터 집계, 수분~수시간 소요)
2. 원하는 데이터를 추출하여 데이터 마트를 구축 후 항상 초 단위의 응답을 얻을 수 있도록 함.(크로스 집계 사용, 수 초 소요)



데이터 처리의 응답이 빠르다 = 대기시간(Latency)이 적다 or 지연이 적다

데이터 마트를 만들 때는 가급적 지연이 적은 데이터베이스가 있어야 함.



지연 적은 데이터베이스 만드는 법

1. 모든 데이터를 메모리에 올리는 것

   - 데이터 용량 규모가 N 기가바이트면 감당 가능할 듯.

   - 하지만 RDB(관계형 데이터베이스)는 메모리가 부족하면 성능 저하 극심함.

2. 압축과 분산에 의해 지연 줄이기(MPP 기술)

   - 데이터를 가능한 작게 압축하고 그 것을 여러 디스크에 분산함으로써 데이터의 로드에 따른 지연을 줄임
   - 분산된 데이터를 읽어들이기 위해 멀티 코어를 활용하면서 디스크 I/O를 병렬처리 하는 것이 효과적
   - 이를 MPP(Massive parallel processing, 대규모 병렬처리)라고 불리움



일반적인 업무에 사용되는 데이터베이스 => 행 지향 데이터베이스, 레코드 단위의 읽고 쓰기 가능

BUT 데이터 분석에 사용되는 데이터베이스 => 열 지향 데이터베이스, 칼럼 단위 집계에 최적화



처리량과 지연시간

- 데이터 웨어하우스, 데이터 레이크 : 대량 데이터 처리를 위해 처리량 우선
- 데이터 마트 : 지연 시간 단축이 우선 순위 => 충분한 메모리 준비 or 디스크 I/O 절감 필수



행 지향 vs 열 지향 데이터베이스

- 행 지향

  - 테이블 각 행을 하나의 덩어리로 디스크에 저장
  - 새 레코드 추가 시 파일의 끝에 데이터 씀 => 약간 스택 느낌
  - 데이터 추가를 효율적으로 할 수 있음

  - 데이터 검색 고속화를 위해 index 존재

- 열 지향

  - 데이터를 미리 칼럼 단위로 정리해 둠
  - 필요한 칼럼만을 로드할 수 있어 I/O 줄이기 가능
  - 데이터 압축 효율도 행 지향 대비 10배 정도 우수



쿼리 지연을 위한 또 다른 방법 - MPP 아키텍쳐에 의한 데이터 처리 병렬화

- 행 지향 DB에서 하나의 쿼리 - 하나의 스레드에서 실행

  - 많은 쿼리 동시 실행 => 여러개의 cpu 코어 활용 가능 BUT 개별 쿼리가 분산처리 되는 것은 아님

- 열 지향 DB => 대량 데이터를 읽으므로 1번의 쿼리 실행 시간 길어짐 + 압축된 데이터의 전개 등으로 CPU 리소스 많이 필요

  => 멀티코어를 통한 고속화 필요

- MPP는 하나의 쿼리를 다수의 작은 테스크로 분해, 이를 가능한 한 병렬로 실행함.



결론 : 수억 레코드를 초과하는 데이터 마트의 지연을 작게 유지하기 위해서는 데이터를 "열 지향 스토리지" 형식으로 저장해야함.



데이터 시각화 위한 도구

1. Jupyter Notebook
   - 에드 훅 분석에 특화
   - matplotlib을  통한 시각화 가능
   - 간이적인 워크플로우 가능

2. 대시보드 도구
   - 정기적으로 쿼리를 실행해 보고서 작성 등에 활용
   - BI 대비 새로운 그래프를 쉽게 추가하는 것이 중시된다.
   - 워크플로우 가능, 최소 하루 한번 자동 갱신 or 실시간 업데이트 가능
   - Redash(sql 기반), Superset(마우스 조작 기반, 대화형), Kibana(Elasticsearch 프론트엔드 기반) 등 존재

3. BI 도구
   - n 개월 단위의 장기 데이터 추이의 시각화 or 집계 조건을 세부적으로 바꿀 수 있음
   - 이미 있는 데이터 가져오기 + 데이터 분석을 쉽게하기 위해 데이터 가공하는 일 존재
   - 알고싶은 것이 늘어날 때 마다 데이터 마트에 테이블을 만들고 거기에서 파생된 다수의 대시보드가 생겨나는 것이 시각화 과정



OLAP(Online Analytical Processing)

- 데이터 집계를 효율화하는 방법 중 하나
- 다차원 모델의 데이터 구조를 MDX(multidimensional expressions) 등의 쿼리 언어로 집계함
- 데이터 분석을 위해 만들어진 다차원 데이터 => OLAP 큐브, 이 것을 크로스 집계하는 구조 => OLAP



MPP 등장 이전 사용되었으나, 요새는 BI 도구 + MPP 데이터 베이스를 조합한 크로스 집계가 증가하는 추세

- MPP DB에는 다차원 모델 개념이 없고, 비정규화 테이블이 이를 대체함.

 



in Table

트랜잭션(transaction) : 시간과 함께 생성되는 데이터를 기록한 것, 변화 X

마스터(master) : 트랜젝션에서 참고되는 각종 정보, 변화 O



in DataWarehouse

팩트 테이블(Fact Table) : 트랜잭션처럼 사실이 기록된 것

디멘전 테이블(Dimension Table) : 거기에서 참고되는 마스터 데이터 등을 담고있는 것



스타 스키마(Start Schema)

데이터 마트를 만들 때 팩트 테이블을 중심으로 여러 디멘젼 테이블이 결합 => 스타 스키마



비정규화(denormalization)

정규화에 의해 분해된 테이블을 최대한 결합하여 하나의 테이블로 정리하려고 하는 것



데이터 마켓에서 스타 스키마가 사용되는 이유

1. 단순한 구조 때문에 이해 쉽고 데이터 분석 쉽게 가능

2. 성능 상의 이유

​	=> 팩트 테이블을 최대한 작게, 나머지는 디멘젼 테이블로 옮기기 => 쿼리 지연 감소에 효과적

​	=> 하지만, 이 문제는 열 지향 스토리지에 의해 해결된다.



데이터 마트에 정규화 테이블은 필요없음



데이터 마트에 스타 스키마 사용된 것은 과거 이야기임

(데이터 웨어하우스의 테이블 구조로는 스타 스키마 우수함)



비정규화 테이블 = 스타 스키마에서 좀 더 비정규화를 진행해 모든 테이블을 결합한 팩트 테이블

데이터 마트는 이 비정규화 테이블로 하는 것이 가장 단순, 효율적임



다차원 모델 : BI 도구의 기본 데이터 모델. 테이블, 칼럼의 집합을 쉽게 정리해 이름 붙인 것

=> 칼럼을 디멘전(숫자데이터, 그 집계 방법을 정의하는 것) / 측정값(크로스 집계에 있어 행과 열을 이용하는 것)으로 분리함



### CH 3



3-1 대규모 분산 처리의 프레임워크

- 구조화된 데이터 : 스키마(테이블의 칼럼, 데이터 형, 테이블간의 관계 등)가 명확하게 정의된 데이터

​	=> 기존의 데이터 웨어하우스에서의 데이터는 항상 구조화된 데이터로 축적

- 비구조화 데이터 : 스키마가 없는 데이터, 자연 언어로 작성된 텍스트 데이터, 이미지, 동영상 등의 미디어 데이터 포함

​	=> 이 상태로는 sql에 집계하기 힘듦.

- 반구조화 데이터 : CSV, JSON, XML => 스키마리스 데이터라고도 불리움. 



비구조화 데이터를 분산 스토리지 등에 저장하고 그 것을 분산 시스템에서 처리하는 것 => 데이터 레이크의 개념

데이터 가공하는 과정에서 스키마 정의 및 구조화된 데이터로 변환함으로써 분석 가능



데이터 구조화의 파이프라인

- 각 데이터 소스에서 수집된 비구조화 데이터 / 스키마리스 데이터 => 초기에 분산 스토리지에 보존.(웹 서버 로그 파일, 업무용 데이터 베이스에서 추출한 마스터 데이터 등 포함)
- 위 데이터는 스키마가 없으므로 sql로 집계 불가능 => 스키마를 명확하게 한 "구조화 데이터"로의 변환 필요
- 구조화데이터 => 열 지향 스토리지로 저장. why? 데이터 압축률을 높이기 위해.
  - MPP 데이터베이스로 전송 or hadoop 상에서 열 지향 스토리지 형식으로 변환함
  - 팩트 테이블 : 시간에 따라 증가하는 데이터
  - 디멘젼 테이블 : 그에 따른 부속 데이터



분산처리 프레임워크(Hadoop and Spark)를 사용하는 이유?

=> 비구조화 데이터를 읽어 들여 열 지향 스토리지로 변환하는 과정에서 데이터 가공 및 압축을 위해 많은 컴퓨터 리소스가 소비되므로.



Hadoop 

- 분산 시스템을 구성하는 다수의 소프트웨어로 이뤄진 집합체
- 대규모 분산시스템 구축을 위한 공통 플랫폼의 역할
- 기본 구성 요소
  - HDFS(Hadoop Distributed File System) : 분산 파일 시스템
  - YARN(Yet Another Resource Negotiator) : 리소스 관리자
  - MapReduce : 분산 데이터 처리
- HDFS(분산 파일 시스템) & YARN(리소스 관리자)
  - Hadoop에서 처리되는 대부분의 데이터 => HDFS에 저장
    - 데이터가 항상 여러 컴퓨터에 복사되도록 함
  - CPU, 메모리 등의 계산 리소스 => YARN에 의해 관리됨
    - "컨테이너"라는 단위로 관리함.(Docker의 그것과는 다른 내용)
    - 분산 어플리케이션이 실행되면 YARN이 클러스터 전체의 부하를 보고 비어있는 호스트부터 컨테이너를 할당함
    - 한정된 리소스로 다수의 분산 어플리케이션이 동시 실행되면 앱 간에 "리소스 쟁탈" 발생
    - 이를 리소스 관리자가 얼마만큼 할당할지 관리함
- MapReduce, Hive(분산 데이터 처리 및 쿼리 엔진)
  - MapReduce
    - YARN 안에서 동작하는 분산 어플리케이션 중 하나
    - 분산 시스템에서 데이터 처리를 실행하는데 사용.
    - 임의의 자바 프로그램 실행 가능하므로 비구조화 데이터를 가공하는데 적합함
  - Hive
    - SQL 등 쿼리언어에 의한 데이터 집계가 목적 시 사용
    - 쿼리를 자동으로 MapReduce 프로그램으로 변환하는 소프트웨어.
  - 두 프로그램 모두 시간이 걸리는 배치 처리에는 적합하나 에드 훅 쿼리를 여러번 실행 시키는 것에는 부적합.



- Tez : Hive 가속을 위한 프로그램

  - MapReduce의 단점인 1회 스테이지가 끝날 때 까지 다음 처리를 할 수 없는 것을 보완.

  - 불필요한 단계 감소 => 처리 짧아짐 + 스테이지 사이의 대기 시간이 없어 처리 전체가 동시에 실행

    => 실행 시간이 단축

- 대화형 쿼리 엔진
  - Hive 강화가 목적이 아닌, 초기부터 대화형 쿼리 실행만 전문으로 하는 쿼리 엔진(SQL 실행이 목적)
  - Impala, Presto
  - 대화형 쿼리 엔진 => 순간 최대 속도를 높이기 위해 모든 오버헤드가 제거되어 사용할 수 있는 리소스를 최대한 활용하여 쿼리 실행.
- 대량의 비구조화 데이터를 가공하는 무건 배치처리 => 높은 처리량으로 리소스를 활용하는 Hive
- 완성된 구조화 데이터를 대화식으로 집계하고자 할 때는 Impala, Presto



Spark

- MapReduce보다 더 효율적인 데이터 처리를 실현하는 프로젝트
- 대량의 메모리를 활용하여 고속화를 실현하는 것.
- MapReduce, Tez => 데이터를 기본적으로 디스크에 기록했음
- Spark => 가능한 한 많은 데이터를 메모리 상에 올린 상태로 두어 디스크에는 아무것도 기록하지 않음.
- Spark는 Hadoop을 대처하는 것이 아닌 MapReduce를 대체하는 것.
- 대규모 처리 + SQL에 의한 대화형 쿼리 실행 + 실시간 스트림 처리 가능





3-2 쿼리엔진

Hive를 통해 데이터 구조화 진행 (비정규화, 스키마리스 데이터 => 구조화 데이터, 열 지향 스토리지)

=> 	Presto를 통해 데이터 집약 진행 (구조화 데이터, 열 지향 스토리지 => 비정규화 테이블, mpp 데이터베이스 등)



Hive에 의한 구조화 데이터 작성

ORC 형식으로 변환 시키는 것이 외부 테이블을 만드는 것 보다 시간 단축이 더 많이 됨(ORC 형식으로 변환시키는 쿼리문 작성에는 시간이 다소 소요되긴 함)



데이터 구조화 종료 후 데이터 마트 구축

=> 테이블을 결합 및 집약시켜 "비정규화 테이블"을 만드는 것이 목표이다.

=> 이 때, Presto, 대화형 쿼리엔진 / Hive, 배치형 쿼리엔진 모두 다 사용 가능



시간이 걸리는 배치 처리는 원칙적으로 Hive를 사용해야 함.

=> 배치형 시스템 사용하는 편이 리소스의 이용 효율을 높일 수 있기 때문



비정규화 테이블을 만드는 것에 오랜시간이 걸리는건 다반사임.

=> 따라서, 효율적으로 쿼리 작성하는 것이 중요해진다.



서브쿼리 안에서 레코드 수 줄이기(팩트 테이블 줄이는 것과 연관)

- Hive 쿼리는 SQL과 흡사하지만, 근본적으로 다름
- Why? Hive는 DB가 아닌 "데이터 처리를 위한 배치 처리 구조"이기 때문
- 따라서, 읽어들이는 데이터의 양을 의식하면서 쿼리를 작성하지 않으면 성능이 안나옴
  - 기초적인 방법으로, 초기에 팩트 테이블을 작게하는 것이 될 수 있다.



데이터 편향 피하기(분산 시스템의 성능 발휘를 위해)

- 데이터의 편차 역시 고속화 방해에 큰 원인 중 하나.
- 분산 시스템 성능 발휘를 위해 데이터 편차를 최소화 하고, 모든 노드에 데이터가 균등하게 분산되도록 해야함.



대화형 쿼리 엔진 Presto : 다수의 컴퓨터에서 실행되는 분산 시스템.

- Hive => 배치형 쿼리 엔진 => 대량 출력을 수반하는 대규모 데이터 처리에 적합함

- 대화형 데이터 처리 => 작은 쿼리를 여러번 실행하는 것에 강점.

  - 쿼리 실행의 지연을 감소시키는 것이 가장 큰 목표

- Presto 특징 -1 : 플러그인 가능한 스토리지 설계

  - Presto는 일반적인 MPP DB와 다르게 전용 스토리지가 없음 => 컴퓨팅 노드와 스토리지가 밀접히 연결되지 않음.

    => Hive와 마찬가직로 다양한 데이터 소스에서 직접 데이터를 가져올 수 있음

  - 하나의 코디네이터, 여러개의 워커로 구성

  - 쿼리는 Presto CLI 등의 클라이언트 = > 코디네이터 로 전송된다.

  - 코디네이터 : 쿼리 분석, 실행 계획 수집 => 워커에게 처리를 분배함.

  - SQL 실행에 특화된 시스템임

  - 일반적으로 분산 결합 실시함. 같은 키를 갖는 데이터는 동일한 노드에 모인다.



데이터 분석의 프레임 워크 선택하기

- MPP 데이터베이스 
  - 완성한 비정규화 테이블의 고속 집계에 적합함.
  - 구조화 데이터를 SQL로 집계하는 것 뿐이라면
	  - 기존의 데이터 웨어하우스 제품과 클라우드 서비스를 이용하는 것이 BEST
  - 스토리지 및 계산 노드가 일체화 되어있음 => 처음 ETL 프로세스 등으로 데이터를 가져오는 절차 필요
  - 그 이후에는 SQL만으로도 데이터 집계 가능
  - 확장 / 유연성 측면에서는 분산 시스템이 유리함
	  - 따라서 이 경우(대량의 텍스트 처리 필요 or 데이터 처리를 프로그래밍 하고 싶은 경우)에는 분산 시스템의 프레임워크 결합할 것.
  - 시각화를 위한 데이터 마트로도 쓰임새 좋음
	  - BI + MPP 데이터 베이스는 오랜 실적 존재함 => 완성한 비정규화 테이블을 고속으로 집계하는데 최적


- HIVE
	- 데이터양에 좌우되지 않는 쿼리엔진
	- 대규모 배치 처리를 꾸준히 실행함
	- 특히 텍스터 데이터 가공 OR 열 지향 스토리지 만드는 등의 무거운 처리에 적합
	- By Tez, 대화용 쿼리에도 사용할 수 있음
	- Hive의 장점 : 안정성 >>>> 대화성

- Presto 
	- 속도 중시 & 대화식으로 특화된 쿼리 엔진
	- Hive와 정반대인 쿼리 엔진
	- 속도를 위해 다른 것을을 희생함
	- 쿼리 실행 중 장애 발생 시 처음부터 재실행 / 메모리 부족 시 쿼리 실행 불가 등의 단점 존재
	- But, 원래 실행이 워낙 빨라서 반복 실행으로 위 단점 상쇄 가능
	- 표준 SQL 준수하므로 일상적인 데이터 분석을 위해 자주 사용하는 쿼리 엔진. 모든 데이터를 SQL로 집계하기 위한 중심 가능
	- 대화식 쿼리에 특화 => 텍스트 처리 중심인 ETL에는 부적합.(이 경우[데이터 구조화] Hive와 Spark 사용)
	- 단시간에 대량의 리소스를 소비하므로 무리한 사용불가 => 시간이 걸리는 처리는 Hive, 클러스터 나누기 등으로 극복하기.

- Spark
	- 분산 시스템을 사용한 프로그래밍 환경
	- 인 메모리의 데이터 처리가 중심
	- 대화형 쿼리 실행에 적합
	- 가장 큰 장점
		- ##### ETL 프로세스에서 SQL에 이르기까지의 일련의 흐름을 하나의 데이터 파이프라인으로 기술할 수 있다는 점
	- 하나의 스크립트 안에서
		- 데이터 구조화 by Hive
		- SQL 실행 by Presto
		위 두 과정 실행 가능
		=> 즉, 텍스트 데이터를 읽어 들여 열 지향 스토리지로 변환하고 그 것을 SQL로 집계하여 결과를 내는 일련의 프로세스를 한번의 데이터 처리로 할 수 있음.
	- 메모리 관리가 중요함.
		- 여러번 사용하는 데이터 => 캐시에 두기 / 디스크에 swap 시키기 등으로 메모리 제어 하기

3-3 데이터 마트의 구축
=> 시각화를 위한 길

- 팩트 테이블 Fact table
	- 빅데이터 분석의 시작 => 데이터 구조화
		- 데이터 구조화에서 압도적인 비율을 차지하는 것 => 팩트 테이블
	-  크기가 작으면 메모리에 올림
		- 그렇지 않으면 열 지향 스토리지에서 데이터를 압축해야함 => 빠른 집계를 위해
	- 작성 방법
		- 추가(append)
			- 새로 도착한 데이터만 추가(insert into)
		- 치환(replace)
			- 과거 데이터를 포함해 테이블 전체를 치환(create table)
		- 효율은 "추가"가 압도적으로 좋으나, 문제점 발생 가능성 존재
			- 해결을 위해 테이블 파티셔닝 진행
	- 
- 테이블 파티셔닝
	- 물리적인 파티션으로 분할
	- 하나의 테이블을 여로 물리적인 파티션으로 나눔
		- 파티션 단위로 정리하여 데이터 추가/삭제 가능
		- 일반적으로 1일 1회 / 1시간에 1회 식으로 자주 파티션 생성 후 팩트 테이블에 붙여놓기
		-  각 파티션은 매번 교체하도록 함 / 존재한다면 덮어쓰기 => 데이터 중복 가능성 배제
	- 데이터 웨어하우스 구축에 유용함

- 데이터 마트의 치환
	- 데이터 마트를 만들 때에는 단순히 팩트 테이블을 치환하는 경우가 많음
		- why? 데이터 양이 한정적이므로
	- 치환 시 중복 가능성 적음 / 쿼리 한번 실행으로 진행 가능 / 스키마 변경에도 유연한 대처 가능 등의 장점이 있으나, "긴 처리 시간" 이라는 단점 존재
	- 데이터 처리가 1시간 이내에 완료가 가능하다면 치환이 옳은 선택(주로)
	
- 집계 테이블 Summary Table
	- 팩트 테이블을 어느정도 모아서 집계한 테이블
	- 레코드 수를 줄일 수 있음
	- 만드는 방법
		- 필요한 칼럼을 골라 숫자 데이터를 집계하면 됨.
	- 카디널리티(cardinality) : 각 칼럼이 취하는 값의 범위
	- 카디널리티를 줄이면 집계 테이블이 작아짐
		- 하지만 무리하게 줄일 시 기존 정보에 큰 손실이 발생
		- 최종 레코드가 수억 건 정도라면 이상 무

업데이트 될 가능성이 있는 테이블(마스터 데이터 등)을 위한 방법 
- 스냅샷 테이블 Snapshot Table
	- 정기적으로 테이블을 통째로 저장하는 방법
	- 다른 팩트 테이블과 결합 시 디멘젼 테이블로도 사용 가능
		- 날짜를 포함해서 결합 시 매일 변화하는 마스터 정보를 이용한 데이터 분석 가능해짐
	- 특정 시점의 테이블의 상태를 기록한 것 => 나중에 다시 만들 수 없음
	=> 데이터 레이크 / 데이터 웨어하우스 같은 영구적인 저장소에 보관 => 삭제 가능성 방지해야 함
	
- 이력 테이블 History Table
	- 변경 내용만을 저장하는 방법
	- 데이터 양을 줄이는 것에 도움됨
		- 하지만, 어느 순간의 완전한 마스터 테이블을 나중에 복원하는 것이 어려움 => 디멘전 테이블로 사용하기는 힘듦

마스터 관계의 테이블은 기본적으로 매일 스냅샷 하는게 권장!

- 데이터 집계의 기본형
	1. 팩트 테이블에서 필요한 데이터 꺼내기
		- 시간에 의한 검색 or 참고하는 칼럼 수 줄이기 => 데이터 로드 속도 빨라짐
	2. 이 것을 디멘전 테이블과 결합하여 데이터 마트에 저장할 칼럼 선택하기
		- 카디널리티를 작게하는 것이 중요
		- 세션 ID 등 다수 값을 갖는 것을 출력에 포함하는 것은 피하기
		- 시각화의 프로세스에서 이용하고 싶은 디멘전만을 추가하기
	3. 그룹화 하여 측정값 집계하기

요약
데이터 
- 비구조화 데이터
	- 텍스트 파일 등
- 스키마리스 데이터
	- json 등
	위 데이터들을 여러 컴퓨터에서 "분산처리"함

분산처리 프레임워크
- Hadoop
	- 분산파일 시스템 / 리소스 관리자 / MapReduce에 의한 분산 데이터 처리 등 종합적인 컴포넌트 제공
	- 많은 분산 애플리케이션의 공통 플랫폼으로 이용됨

- Spark
	- 대량의 메모리를 활용한 고속의 데이터 처리 기반
	- MapReduce를 대체하는 분산 프로그래밍 환경

SQL-on-Hadoop : Hadoop과 Spark를 이용해 SQL을 실행하기 위한 것
- Hive
	- 디스크 상에서 대량의 데이터 처리 => 대규모 배치 처리에 적합
- Presto 
	- 메모리 상에서의 고속 집계에 특화 => 대화형 쿼리 실행에 적합

=> 데이터 구조화 종료

데이터 마트 구축
- 팩트 테이블 + 디멘전 테이블 => 결합 및 집계
	- 시각화에 적합한 비정규화 테이블 만들기
- 디멘전으로 사용하는 데이터는 정기적인 스냅샷으로 이력 축적
- 커디널리티만 작아지면 비정규화 테이블 아주 작게 집약 가능



### CH4 빅데이터 축적

4.1 벌크형과 스트리밍 형의 데이터 수집

빅데이터 => 확장성이 높은 분산 스토리지(distributed storage)에 저장됨
	=> 기본적으로 대량의 파일을 저장하기 위한 객체 스토리지(object storage).

- 객체 스토리지
  - 파일 읽고 쓰기 => 네트워크를 걸쳐 실행
    - 내부 처리에 다수의 물리적인 서버 + 하드 디스크 존재
    - 읽고 쓰기를 다수의 하드에어에 분산 => 데이터의 양이 늘어나도 성능 변화 없음
  - 데이터 양이 많을 때는 우수 => But 소량의 데이터에는 비효율적
    - why? 데이터 양에 비해 통신 오버헤드가 너무 클 수 있기 때문

시계열 데이터 : 시간과 함께 생성되는 데이터

- 데이터 수집
  - 수집한 데이터를 가공하여 집계 효율이 좋은 분산 스토리지를 만드는 일련의 프로세스
    - 데이터 수집 / 구조화 데이터 작성 / 분산 스토리지에 대한 장기적인 저장 모두 포함됨
  - 시계열 데이터를 객체 스토리지에 기록하면 대량의 작은 파일 생성
    - 결과적으로 시간이 지남에 따라 성능을 저하시킴
    - 따라서, 적당히 모아서 하나의 큰 파일로 만드는 것이 효율 증진에 도움

  - 파일이 지나치게 클 경우에도 문제 생김
  - 객체 스토리지에서 효율적으로 처리할 수 있는 크기 : 1MB ~ 1GB

빅데이터는 단순히 수집만 해서는 X
	=> 나중에 처리하기 쉽도록 준비해야함!


- 데이터 구조
  - 벌크 형 
    - 전통적인 웨어하우스에서 사용
    - DB / 파일 서버 / 웹 서비스 등에서 SQL, API 등으로 정리해 데이터를 추출
    - 기존의 DB, 이미 대량의 데이터가 축적된 경우 사용
    - 데이터가 처음부터 분산 스토리지에 저장 되어있지 않으면 데이터 전송을 위한 "ETL 서버" 설치
      - 구조화된 데이터 처리에 적합한 데이터 웨어하우스를 위한 ETL 도구
      - 오픈 소스의 벌크 전송 도구
      - 손수 작성한 스크립트
		  등을 이용해 데이터 전송
	- ETL 프로세스는 주로 하루 or 1시간마다의 간격의 정기적인 실행 or 일정 크기로 축적된 데이터 모음
    	- 위 작업은 주로 워크플로로 진행
  	- 데이터 전송의 신뢰성에 유리한 데이터 구조
    	- 뭔가 문제가 생겼을 때 여러 번 데이터 전송 재실행 가능
  	- 따라서, 과거 데이터 빠짐없이 가져오고 싶다 or 실패한 작업을 재실행 할 것을 고려한다 => 벌크 형 전송 추천
  
  - 스트리밍 형
    - 계속해서 전송되어 오는 작은 데이터를 취급하기 위한 데이터 전송
    - 주로 웹 브라우저 / 모바일 앱 / 디바이스 등에서 데이터를 수집하는 경우에 선호
      - why? 다수의 클라이언트에서 계속해서 작은 데이터가 전송되는 형태이므로 = 메시지 배송(message delivery)
        - 전송되는 데이터 양에 비해 통신을 위한 오버헤드가 커짐 => 이를 처리하는 서버에게 높은 성능을 요구함
      - 작은 데이터 쓰기에는 NoSQL이 유리
        - 이 경우 Hive 같은 쿼리 엔진으로 NoSQL DB에 연결해 데이터 읽기 가능
      - 분산 스토리지에 직접 쓰는 것이 아니라, 메세지 큐 / 메세지 브로커 등의 중계 시스템에 전송 가능
        - 기록된 데이터는 일정한 간격으로 꺼내고 모아서 함께 분산 스토리지에 저장
    - 웹 브라우저에서의 메시지 배송
      - 웹 서버 안에서 메시지를 만들어 배송함
        - 전송 효율을 높이기 위해 서버상에서 일단 데이터 선축적 후 모아서 보냄.
        - Fluentd or Logstash 같은 "서버 상주형 로그 수집 소프트웨어"가 사용됨
      - 자바 스크립트 사용 => 웹 브라우저에서 직접 메세지 보냄
        - 웹 이벤트추적(Web Event Tracking)
        - HTML 페이지에 태그 삽입
        - 수집된 데이터는 서버로 전송 or API 경우로 함께 취득해 분산 스토리지에 저장

	- 모바일 앱으로부터의 메시지 배송
    	- 웹 브라우저와 동일한 통신방법, HTTP 프로토콜, 을 사용하므로 웹 브라우저와 동일한 메시지 배송 방식
    	- 서버를 직접 마련하는 것이 아닌 MBaaS(Mobile Backend as a Service)라는 백엔드 각종 서비스 이용 가능
        	- 이 경우, 백 엔드 데이터 저장소에 저장한 데이터를 벌크형 도구를 사용해 꺼냄
    	- 혹은 모바일 앱에 특화된 액세스 해석 서비스를 통해 이벤트 데이터 수집
        	- 웹에서의 자바 스크립트를 사용하는 방법과 유사한 듯(내 개인적인 생각)
			- 모바일 용 개발 키트(SDK)를 사용해 메시지 보냄
        	- 발생 이벤트는 우선 SDK에 축적, 온라인 상태가 되었을 때 모아서 보냄
        	- SDK 사용 시 데이터 중복에 대한 방안 마련 필수
  	- 디바이스로부터의 메시지 배송
    	- MQTT(MQ Telemetry Transport)
        	- TCP/IP를 사용하여 데이터를 전송하는 프로토콜의 하나
        	- 일반적으로 Pub/Sub 형 메시지 배송 구조
            	- Pub : Publish, 전달
            	- Sub : Subscription, 구독
            	- 채팅 시스템, 메시징 앱 or 푸시 알림 등의 시스템에서 사용
        	- 관리자에 의해 토픽(Topic) 생성
            	- 메시지를 송수신 하기 위한 대화방의 느낌
          	- 토픽 구독 시 메시지 도착함
          	- 토픽 전달 시 구독 중인 모든 클라이언트에게 보내짐
            - 메시지 교환 중계 서버 : MQTT 브로커
            - 메시지 수신 시스템 : MQTT 구독자
            - 네트워크에서 분리된 경우에도 나중에 재전송 하는 구조가 프로토콜 수준에서 이미 고려됨(HTTP는 직접 생각해야함)
    - 전체적인 맥락 요약
      - 클라이언트 (Client) : 메시지가 처음 생성되는 기기
      - 프런트 엔드 (Front End) : 해당 메시지를 먼저 받는 서버
        - 목적 : 클라이언트와의 통신 프로토콜을 제대로 구현하는 것
        - 암호화 / 사용자 인증 및 높은 확장성 필요
        - 단지 데이터를 받는 것에만 전념 => 그 이후는 백엔드에서!
      - 프런트 엔드가 받은 메시지 => 메시지 브로커로 전송 => 그 이후 분산 스토리지에 데이터 저장됨(추후 과정 존재)


4.2 [성능x신뢰성] 메시지 배송의 트레이드 오프

- 메시지 브로커
  - 스토리지의 성능 문제를 해결하는 중간층
  - 데이터를 종종 일시적으로 축적함
    - 이를 통해 분산 스토리지에 쓰는 속도를 안정화함
  - 오픈소스 - Apache Kafka / 클라우드 서비스 - Amazon Kinesis 주로 활용
  - 데이터 브로커 => 데이터의 쓰기 속도를 조정하기 위한 완충 부분 / push -> pull 형으로 메시지 배송의 타이밍을 변환함
  - push : 송신 측의 제어로 데이터를 보내는 방식
    - 생산자 (producer) : 메시지 브로커에 데이터를 push하는 것
  - pull : 수신 측의 주도로 데이터를 가져오는 것
    - 소비자 (consumer) : 메시지 브로커에 데이터를 pull하는 것
  - 스트림 처리 (stream processing) : 짧은 간격으로 차례대로 데이터를 꺼내서 처리하는 것
    - 프런트 엔드에서는 메시지 브로커에 데이터를 push / 그것으 소비자에서 모아서 가져옴
  - 메시지 라우팅 (message routing) : 메시지 브로커에 넣은 데이터는 복수의 소비자에서 읽어드릴 수 있음 => 메시지가 복사되어 데이터를 여러 경로로 분기시키는 것

- 메시지 배송에 대한 신뢰성
  - at most once : 메시지는 한 번만 전송. 그러나 도중에 전송이 실패해서 사라질 가능성 존재  
    - 무슨 일이 일어나도 매시지 재전송 없음
  - exactly once : 메시지는 손실되거나 중복 없이 한 번만 전달됨
    - 네트워크 상 분단된 두 개의 노드의 통신을 보장하는 코디네이터(coordinator) 존재
      - 이 것으로 송신 측과 수신 측 모두 서로의 정보를 전달 => 문제 발생 시 coordinator의 지시에 따라 해결
      - 문제점
        - 분산 시스템에서 코디네이터가 항상 존재한다고 가정할 수 없음
        - 시간이 지나치게 많이 소모됨
  - at least once : 메시지는 확실히 전달되나, 같은 것이 여러번 전달 될 가능성 존재
    - 대부분의 배송 시스템이 가지고 있음
    - 중복제거를 사용자에게 맡김
    - 중복 제거 방법
      - 오프셋을 이용한 중복 제거
        - 전송해야 할 데이터에 파일명 등의 이름을 부여해 그 것을 작은 메시지에 실어서 배송
        - 각 메시지에는 시작위치(오프셋) 존재
        - 메시지가 중복되어도 같은 파일 - 같은 장소를 덮어쓰는 것이므로 문제X
        - 벌크형 데이터 전송에는 적합하나 스트리밍에는 어울리지 않음
      - 고유 ID에 의한 제거
        - 스트리밍 형에서 주로 사용됨
        - 과거 받은 모든 데이터에 대한 ID를 기억하진 않음
        - 두 방법
          - 분산 스토리지로 NoSQL DB 사용
          - SQL로 중복 제거
  - 종단간(End to End) 신뢰성
    - 메시지 배송의 중간 경로를 모두 at least once로 통일 후 클라이언트 상에서 모든 메시지에 고유 ID를 포함하다록 하고 경로의 마지막에서 중복제거를 실행해야함.

- 데이터 수집의 파이프라인
  - 통신 프로토콜 구현
  - 메시지 브로커(쓰기 성능의 안정화)
  - 소비자 (정기적으로 파일 생성)
  - 분산 스토리지
  - 중복 제거
  - 데이터 구조화 - 열지향 스토리지로 변환



4.3 시계열 데이터의 최적화

이벤트 시간 : 클라이언트 상에서 메시지가 생성된 시간

프로세스 시간 : 서버가 처리하는 시간

이벤트 시간에는 딜레이가 생길 수 있음 => 문제 야기할 수 있음



풀 스캔(Full scan) : 다수의 파일을 모두 검색하는 쿼리, 시스템 부하를 크게 높이는 원인



이벤트 시간 취급을 효율화 할 수 있는 방법

- 시계열 인덱스(time-series index)

  - 이벤트 시간에 대한 인덱스를 만드는 것
  - 매우 짧은 범위의 특정 시간에 맞춘 데이터 집계를 빠르게 실행할 수 있음
  - 정해진 시간에 발생한 이벤트를 조사 or 실시간 대시보드를 만드는 경우에 유용
  - 장기간에 걸쳐 대량의 데이터를 집계하는 경우 => 분산 스토리지보다는 집계 효율이 높은 열 지향 스토리지를 지속적으로 만들어야 함

- 조건절 푸쉬다운(predicate pushdown)

  - 필요 최소한의 데이터만을 읽도록 하는 최적화
  - 열 지향 스토리지를 만들 때 가급적 읽어들이는 데이터의 양을 최소화 함.
  - 이는 조건절 푸시다운에 의한 최적화를 작동시켜 풀 스캔을 피할 수 있게 됨.
  - 최대한 활용하려면 집계 시의 데이터 로딩이 최소한으로 끝날 수 있도록 다수의 연속된 데이터를 한 곳에 배치해야 함
  - 즉, 데이터를 충분히 연속적으로 배치해야 최적화 효과를 높일 수 있음

  - 짧은 주기로 열 지향 스토리지를 만들 시(1분 등) 다수의 파일로 데이터가 분산되므로 데이터의 로드가 빈번하게 발생.

- 이벤트 시간에 의한 분할

  - 시계열 테이블 (time series table) : 시간을 이용해 분할된 테이블
  - 시계열 테이블에 데이터를 어떻게 추가하느냐에 따라 성능 결정
  - 작은 데이터를 효율적으로 추가할 수 있는 분산 데이터베이스를 사용 or 너무 오래된 데이터는 버리는 아이디어 필요

- 데이터 마트만을 이벤트 시간으로 정렬

  - 데이터 수집 단계에서는 이벤트 시간 고려 X, 프로세스 시간만을 사용하여 데이터 저장
  - 데이터 마트를 만드는 단계에서 이벤트 시간에 의한 정렬 함께 하도록 함



4-4 비구조화 데이터의 분산 스토리지

No SQL

분산 스토리지 for 빅데이터 => 필요에 따라 얼마든지 확장할 수 있는 확장성 + 데이터를 구조화하지 않고도 저장할 수 있는 유연성 필요

객체 스토리지의 단점

	1. 객체 스토리지 상 파일은 교체가 어려움
    - 로그 파일처럼 변경 가능성이 없는 파일은 상관없으나, DB처럼 수시로 변경하는 용도로는 적합하지 않음
    - 쓰기 빈도가 높은 데이터는 별도 RDB에 저장 and 정기적인 스냅샷 or 다른 분산 데이터베이스에 저장하도록 해야 함.
    - 중요 데이터는 트랜잭션 처리에 대해 고려된 데이터베이스에 기록하는 것이 원칙임
    - 스트리밍 형의 메시지 배송 등은 트랜잭션 처리가 이뤄지지 않기 때문에 확실한 기록을 보증하는 것이 어려움
	2. 객체 스토리지에 저장된 데이터를 집계할 수 있게 되기까지는 시간이 걸림
    - 열 지향 스토리지를 만듦 => 집계의 고속화 OK, But ! 그 작성에는 시간 소모 큼.

No SQL DB : 특정 용도에 최적화된 데이터 저장소



ACID 특성 vs CAP 정리

- ACID 특성 : 트랜잭션 처리에 요구되는 네 가지 성질

  - 원시성(atomicity) 
  - 일관성(consistency)
  - 독립성(isolation)
  - 내구성(durability)

  일반적인 RDB는 위 사항을 충족함 => 신뢰성 있는 트랜잭션 처리를 실현 중

- CAP 정리 : ACID 특성을 만족하며 분산 시스템을 구축하는 것은 어려우므로 그 한계에 대해 제창된 것
  - 일관성(consistency)
  - 가용성(availability)
  - 분단내성(partition-tolerance)

- 결과 일관성
  - NoSQL DB 중 일부는 일관성, 가용성 중 하나를 선택함
    - 일관성 pick => 단 시간의 장애 발생을 수용
    - 가용성 pick => 오래된 데이터 읽을 수 있음
  - 자주 볼 수 있는 것 : 결과 일관성, "써넣은 데이터를 바로 읽을 수 있다고는 말할 수 없다."



- 분산 KVS(distributed Key-Value Store)

  - 모든 데이터를 키값 쌍으로 저장하도록 설계된 데이터 저장소

  - 몇 kb 정도의 데이터를 초당 수만 번 읽고 쓰는 경우의 데이터가 대상

  - 모든 데이터에 고유 키를 지정, 그 것을 부하 분산을 위해 이용함

  - 키 정해진 후 그 값을 클러스터 내의 어느 노드에 배치할 것인지 결정

  - 이 구조에 의해 노드 간에 부하 균등 분산 후 노드 증감만으로 클러스터의 성능을 변경할 수 있게 되어 있음

  - Key - Value 는 1:1 / 1:N / N:1 등 여러 경우가 가능, 시스템에 좌지우지 됨

    - 마스터/슬레이브 형
      - 1대의 마스터가 전체를 관리
      - 마스터가 중지되면 아무도 데이터 읽기/쓰기 안됨
    - P2P형 시스템
      - 모든 노드가 동등한 관계
      - 클라이언트는 어떤 노드에 연결해도 데이터를 읽고 쓸 수 있음

  - Amazon DynamoDB

    - AWS에서 사용
    - 항상 안정된 읽기, 쓰기 성능을 제공하도록 디자인된 NoSQL 데이터 베이스
    - 하나, 두 개의 키에 연결하는 형태. 임의의 스키마리스 데이터 저장 가능
    - P2P형의 분산 아키텍쳐
    - 미리 설정한 초 단위의 요청 수에 따라 노드 증감됨
      - 따라서 데이터 읽기, 쓰기에 지연이 발생하면 곤란한 앱에 유용함
    - 데이터 분석을 위해 Amazon EMR, Amazon Redshift 등과 결함 => Hive에 의한 배치 처리를 실행 or 데이터 웨어하우스에 데이터를 전송
    - DB Streams 사용 시 데이터 변경을 이벤트로 외부에 전송 => 실시간 스트림 처리 가능

  - 일반적으로 NoSQL DB는 앱에서 처음에 데이터를 기록하는 장소로 이용됨

  - 데이터 분석을 위해서 외부로 데이터를 추출해야 함

    

- 와이드 칼럼 스토어(wide-column store)

  - 분산 KVS를 발전시켜 2개 이상의 임의 키에 데이터를 저장할 수 있도록 한 것
  - 성능 향상이 목적임
  - Google Cloud Bigtable / Apache HBase / Apache Cassandra 등이 이 것에 속함

  - 하나의 테이블에 가로, 세로의 2차원(그 이상 차원도 오케이)에 데이터를 쓸 수 있도록 한 것.
  - Apache Cassandra
    - SQL과 동일한 감각으로 테이블 조작 가능
    - 구조화 데이터만 취급 가능
    - -2- 형의 분산 아키텍쳐
    - 지정한 키에 의해 결정한 노드에 해당 키와 관련된 모든 값 저장
    - 다수의 독립적인 키가 있을 시 처리 분산 더 잘함
    - 데이터를 집계하는 것에는 적합X => 집계를 위해서는 Hive, Presto, Spark 등을 사용해서 데이터 추출해야 함

- 도큐먼트 스토어(document store)

  - 데이터 처리의 유연성이 목적
  - Json처럼 복잡한 스키마리스 데이터를 그대로의 형태로 저장 및 쿼리 실행 가능하게끔 함
  - 배열과 연상 배열과 같은 중첩된 데이터 구조에 대해 인덱스를 만들거나 도큐먼트 일부만을 치환하는 식의 쿼리 쉽게 실행 가능
  - 스키마를 정하지 않고 데이터 처리 할 수 있음 => 외부 데이터 저장하는 데 적합함
  - 참고 시스템의 데이터 및 로그 저장 등에 적합함

  - MonggoDB
    - JavaScript, 각종 프로그래밍 언어를 사용해 데이터 읽고 쓰기 가능
    - 데이터 분석이 목적은 아님 => 이를 위해선 쿼리 엔진으로부터 접속하는 데이터를 추출해야 함

- 검색 엔진(search engine)

  - 텍스트 데이터 및 스키마리스 데이터를 집계하는 데 자주 사용됨
  - 역 색인(inverted index)을 만들어 검색을 고속화 함
    - 텍스트에 포함된 단어를 분해하고 어떤 단어가 어떤 레코드에 포함되어 있는가 하는 인덱스
    - 모든 텍스트를 전체 스캔하지 않도록 함
  - 데이터 집계에 적합함
  - Elasticssearch
    - 임의의 Json 데이터 저장 가능
    - 아무것도 지정하지 않으면 모든 필드에 색인이 만들어짐
    - 텍스트 데이터에는 역 색인 구축
  - Spunk
    - 텍스트 데이터 집계를 위한 도구
    - 비정형 데이터에 강함, 웹서버, 네트워크 기기 등으로 부터 출력되는 로그 파일, json 파일을 다룸



정리

빅데이터를 효율적으로 집계하기 위해선 **장기적인 데이터 분석을 가정한 스토리지를 만드는 것이 필수**

너무 자주 데이터 복사 => **집계효율 악화**

- 벌크형 데이터 => 한꺼번에 많은 양 복사하므로 크게 상관 없음
- 스트리밍형 데이터 => 작은 메시지가 대량으로 들어오므로 대책 필요

From 다수의 클라이언트 => 실시간으로 데이터를 수집하는 데에 **메시지 배송 방식** 사용됨

**메시지 브로커** 

- 분산 스토리지에 쓰는 속도 안정화 가능
- 메시지를 여러 경로로 라우팅 => 동일한 데이터를 스트리밍 처리 및 배치 처리 모두에서 사용 가능



메시지 배송

- 효율 중요함
- 따라서 트랜잭션 처리를 하지 않는 경우 많음
  - 잠재적으로 데이터 중복, 누락될 가능성 존재
  - 일반적으로 누락을 피하고자 at least once의 데이터 전송
  - 약간의 중복은 허용, 신뢰성이 요구되는 부분에서는 벌크형의 데이터 전송 진행
  - 

NoSQL DB같은 분산스토리지 => 메시지 배송을 하지 않을 때

- 데이터 읽기 쓰기는 우수, But 데이터 집계는 안됌
- 집계 => 쿼리 엔진과 연결하여 애드 훅 분석 or 정기적으로 데이터를 꺼내 장기적인 데이터 분석 준비

