# HDFS와 MapReduce / Pig / Apache Spark



클러스터 =-> 일종의 서버 같은 느낌인 것 같다. 큰 데이터 창고 같은 느낌이 강함



Name Node : 노드를 추적해준다

Data Node에 무엇이 있는지 Name Node에 저장된다.



이름노드는 하나만 활성화가 되어야 하는 것 같다.

그렇지 않다면 읽고 쓰는 것에 큰 문제가 생기는 것으로 보인다.





MapReduce

데이터를 클러스터에 걸쳐 병렬처리하게 도와준다



MapReduce 

mappers and reducers 작성

처리 순서

데이터 불러오기 => mappers => merge sort => reducers



Pig

=> mappers 와 reducers를 작성하지 않아도 데이터 분석 가능

MapReduce의 가장 큰 단점은 시간이 오래 걸린다는 것임

Pig를 통해 이를 극복할 수 있음

Pig는 절차형 언어이다.

스크립트로 단계별로 데이터간에 여러 관계를 설정한다

또한 Pig는 SQL 과 비슷한 역할을 한다

이를 통해 MapReduce 작업을 더 쉽게 간소화 할 수 있다.



PigLatin를 사용

Mapreduce와 Tez 모두와 호환한다



Pig와 관계형 데이터베이스의 차이점은 데이터를 불러올 때 스키마가 적용되는지 여부이다.

Pig는 텍스트 데이터를 불러와 AS 를 사용해 각 필드에 이름 부여가 가능하다



Tez가 Mapreduce보다 훨씬 빠르다





Spark

대규모 데이터 처리에 사용되는 신속하고 보편적인 엔진

 자바, 파이썬, 스칼라 등으로 스크립트를 작성할 수 있는 유연성을 제공하고 복잡한 데이터를 조작, 변형, 분석할 수 있음

머신러닝, 데이터 마이닝, 분석, 데이터 스트리밍 등의 복잡한 작업 가능

속도적인 측면에서 정말 빠름

Mapreduce는 할 수 있는 일이 한정적이나 spark는 아님

클러스터에 어떻게 분배할지 덜 신경써도 된다 => Why? Spark가 알아서 해줌



"회복성 분산 데이터(RDD)" 기반으로 구축되어 있음

=> 기본적으로 데이터 세트를 나타내는 객체이다

RDD 객체에 다양한 함수 적용 가능



Scala를 사용하는 것이 아마 Spark를 가장 효율적인 것 같음



RDD, Apache Spark의 핵심 기술

=> 회복성 분산 데이터 세트의 약자로서 Spark 내부에서 일어나는 지저분한 일들을 추상적으로 표현한 것.

작업을 클러스터에 고르게 분산하고, 실패 시 회복할 수 있으며 사용자에게 "데이터 세트"로 보인다



 pig와 비슷하지만 spark가 좀 더 강력하다

실행되기 전까지 아무 일도 일어나지 않는다 => 이것이 Spark가 속도가 빠른 이유



DataFrame이 Spark에서 하는 일은 RDD를 DataFrame 객체로 확장하는 것

=> DataFrame에는 행 객체가 있고 그 행에는 구조화된 데이터가 들어있음



DataSet은 좀 더 포괄적인 방법이자 선호되는 방법이다



