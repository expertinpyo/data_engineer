 # 데이터 엔지니어링 -2 220610



## 개념

데이터 사이언티스트를 보조하는 일이 데이터 데이터 엔지니어로서의 길임

데이터베이스, 대규모 처리 시스템과 같은 아키텍쳐 구성, 테스트 및 유지하는 역할



데이터 엔지니어는 데이터 대량 처리에 초점을 둔다

기계 클러스터의 사용



데이터 품질 보호

클라우드 기술 등



### 데이터 엔지니어 묘사

1. 데이터베이스 시스템의 전문 사용자임 / 작업은 주로 데이터베이스에서 일어날 것임

   - 데이터베이스 : 많은 양의 데이터를 보유하는 컴퓨터 시스템

2. 데이터를 신속하게 처리할 수 있는 도구를 사용함

   - 데이터 처리, 합병 등을 할 때 엄청난 양의 데이터를 처리함

   - 따라서 한 컴퓨터에서 데이터를 처리하는 대신, 기계 클러스터(여러 대의 컴퓨터들이 연결되어 하나의 시스템처럼 동작하는 컴퓨터들의 집합)를 사용해서 데이터를 처리한다.

     => 기본 아키텍쳐를 추상화함 + 간단한 api를 가짐

   - 

3. 스케쥴링 => 데이터가 특정 간격으로 정확한 시간에 한 장소에서 다른 장소로 이동하는지 여부를 확인함

   => 이런 작업이 적시에 실행되고 올바른 순서로 진행되는지를 확인한다.



위 업무를 진행하기 위해

데이터 베이스 : MySql, PostgreSQl

데이터 처리 : Spark, Hive

스케쥴링 : Apache Airflow,Oozie, Cron

등의 도구를 사용한다



### Cloud Providers

데이터 엔지니어들은 클라우드 컴퓨팅을 정말 많이 사용한다

예전에는 데이터 처리에 의존했던 회사가 자체 데이터센터(클러스터 등)를 소유했었음

비용 처리 등도 다 자회사에서 했었음

 

리소스 낭비 => 클라우드 서비스가 매력적이게 된 계기

따라서, 비용 최적화 때문에 많은 기업들이 클라우드 서비스를 이용하게 된다.



또한, 데이터 베이스의 안정성(물리적으로 위협을 받을 만한 상황이 줄어듦) 역시 클라우드의 가장 매력적인 요소 중 하나이다.



클라우드 서비스를 공급하는 회사는 크게

AWS / Azure / Google Cloud



이들이 제공하는 서비스 => Storage, Computation, Database



[1] Storage => 모든 유형의 파일을 클라우드에 업로드 할 수 있음, 일반적으로 저렴함

AWS S3 / Azure Blob Storage / Google Cloud Storage

[2] Computation  => 클라우드에서 Computation 실행 가능, 일반적으로 가상 머신을 시작하고 원하는 대로 이용 가능

웹서버를 호스팅 하는 등에 사용됨

AWS EC2 / Azure Virtual Machines / Google Compute Engine

[3] Database Hosting

AWS RDS / Azure SQL Database / Google Cloud SQL







## 툴

데이터 엔지니어 = 데이터베이스가 목숨

정보 저장에 데이터 베이스 사용



데이터 베이스 

- 데이터를 보유함
- 데이터를 구성함, 데이터베이스 유형간 조직 수준에 차이가 있음
- 데이터를 빠르게 검색하는데 도움이 됨 => DBMS



데이터베이스 vs 파일 시스템

- Very organized / Less organized
- 검색, 복제 등과 같은 복잡한 데이터 작업의 추상화 / 이런 기능 덜 호스팅 함



구조화된 데이터 vs 구조화되지 않은 데이터



##### 구조화 데이터

- 데이터 베이스 스키마

- 관계형 데이터베이스의 테이블



##### 비구조화 데이터

- 스키마 없음, 그냥 파일 같음
- 사진, 동영상 같은 것들
- 



##### 반구조화 데이터(semi structured)

- JSON



SQL vs NoSQL

##### SQL

- table => 데이터 형성

- Database Schema => 테이블 간의 관계 정의

- 관계형 데이터베이스

  

##### NoSQL

- 비관계형 데이터베이스

- 구조화 or 비구조화

  

스키마 : 데이터베이스의 구조와 관계를 설명함





### 병렬 컴퓨팅 (Parallel Computing)

최신 데이터 처리 도구의 기초를 형성함

메모리 문제 때문에 빅데이터에서 중요 개념으로 부상함



빅데이터 처리 시 데이터를 여러개의 작은 하위 작업으로 분할함

=> 처리 도구는 해당 하위 작업들을 여러 컴퓨터에 배포함

=> 모든 컴퓨터가 더 작은 하위 작업에서 병렬로 작동하기 때문에 전체 작업이 더 빠르게 수행된다.



장점

- 추가 처리 능력

- 한 컴퓨터의 메모리에 모든 데이터를 로드할 필요 없이 데이터를 분할하고 하위 집합을 다른 컴퓨터의 메모리에 로드할 수 있음

  => 컴퓨터 당 메모리 사용량이 상대적으로 적음

  => 데이터는 RAM에 들어갈 수 있음



단점

- 마지막 단계로 여러 컴퓨터에서 하나로 합쳐질 때 추가 비용 및 시간 소모 발생
- 일부 작업은 오버헤드로 인해 속도가 선형적으로 증가하지 않음



### 병렬 컴퓨팅 frameworks

MapReduce / HDFS



- HDFS : 분산 파일 시스템, 컴퓨터에 있는 파일들과 비슷함. 차이점 : 파일이 여러 다른 컴퓨터에 있다는 점
- MapReduce : 대중화된 최초의 빅 데이터 처리 패러다임 중 하나

​	=> 작업을 하위 작업으로 나누고 여러 처리 장치간에 워크로드와 데이터를 분배함.

​	=> 처리장치는 클러스터의 여러 컴퓨터

그러나 MapReduce는 결함(작업 작성하는 난이도가 너무 어려움) 존재

=> 극복하기 위해 Hive 등장



Spark

=> 클러스터 간에 데이터 처리 작업을 배포함

메모리에서 가능한 많은 처리를 유지하려고 함

MapReduce 한계에 대한 해답



스파크는 RDD 에의존한다

RDD(Resilient distributed datasets)

=> 탄력적인 분산 데이터 세트, 여러 노드간에 분산된 데이터를 유지한다

RDD에는 DataFrame과는 다르게 명명된 열이 없음

RDD는 개념적으로 튜플 목록에 가까움



Hive : SQL 추상화를 사용

Spark : DataFrame 추상화를 사용



### Work Scheduling frameworks

위 작업을 통합하는 것이 워크 플로 스케쥴링 프레임 워크



DAG(Directed Acyclic Graph) 



주로

Linux(cron, 선호되지는 않음)

Spotify(Luigi)

Apache Airflow





## ETL