데이터 엔지니어 기업 별 필요 역량



## [토스 증권]

#### Data Enginner (platform)



##### 주요 업무

- 증권 서비스에서 활용되는 다양한 데이터를 처리하고 제공하는 역할을 합니다.
- 안정적이고 효율적인 데이터 파이프라인과 데이터 기반 서비스를 개발하고 운영합니다.
- 대용량의 데이터를 실시간으로 분산처리하여 데이터 기반 토스 서비스에 기여합니다.
- 동료들의 안정적이고 효율적인 데이터 실험/분석 환경을 위한 도구를 개발하고 운영합니다.
- 데이터 분석 및 플랫폼 운영을 위한 다양한 데이터 어플리케이션을 개발합니다.



##### 필요 역량

- 대용량 데이터 처리를 위한 데이터 파이프라인(수집/처리/분석) 개발 경험
- 대용량 분산 시스템(Hadoop, Kafka, Spark 등) 활용 경험
- 데이터 어플리케이션 개발을 위한 소프트웨어 개발 역량(Java, Scala, Python 등)
- Devops(k8s, argocd, ansible, git 등)에 대한 경험 or 기술
- 새로운 기술에 대한 관심이 많고 실제 서비스에 적용하여 개선한 경험
- 다양한 상황에서 최적의 솔루션을 찾을 수 있는 문제해결능력 및 원활한 커뮤니케이션 역량
- 추천/광고/ML 관련 서비스를 개발해보신 분



##### 우대사항

[이력서는 이렇게 작성하시는 걸 추천해요]

- 일반적인 방법으로 처리하기 힘든 대규모 데이터셋이나 비정형 데이터를 다루어 본 경험이 있다면 이력서에 작성해주세요.
- 복잡한 데이터 파이프라인을 잘 관리하기 위해 자동화나 모니터링 환경을 구성한 경험이 있다면 작성해주세요.
- 데이터 기반 서비스를 개발해 본 경험을 적어주시면 좋습니다.
- 새로운 시도를 통해 풀기 힘들었던 문제를 해결하거나 개선을 이루어낸 경험을 적어주시면 좋습니다.



##### 회사에서 사용 중인 기술

- 대량의 데이터를 효율적으로 처리하고 데이터/ML 서비스 운영을 위한 다양한 오픈소스 기반의 플랫폼(Hadoop, Kafka, k8s, MLops)
- Hadoop Ecosystem 기반의 데이터 플랫폼 운영 중
- 사용하는 주요 컴포넌트는 Hadoop, Spark, Impala, Hive, Kudu, Kafka, Airflow, Jenkins, k8s / 내부 인터널 툴도 개발하고 운영 중
- 실시간 처리는 KSQL과 Kudu를 이용하여 이벤트를 검출하거나 결과를 전달



#### Data Enginner (Analytics)



##### 주요 업무

- 토스증권의 Data Engineer (Analytics)는 국내, 해외 종목, 주식매매 등 증권 서비스의 다양한 데이터를 활용하기 위한 DW/Mart 테이블을 설계하고, 데이터 파이프라인을 개발하고 운영해요.
- 대용량의 실시간 데이터를 빅데이터 플랫폼과 분산처리 기술 등을 활용하여 빠르고 효율적으로 처리하고, 이를 기반으로 Data Warehouse를 구축해요.
- 쉽고 빠르게 분석할 수 있도록 효율적인 DW 구조를 설계하고, 자동화를 통해 안정적인 데이터 환경을 구축해요.
- 빠르게 성장하는 서비스에서 꼭 필요한 데이터 처리 업무들을 동료들과 논의하여 주도적으로 해결해요.



##### 자격 요건

- Hadoop-Ecosystem, Database, Data Warehouse에 대한 기본적인 이해가 있으신 분이 필요해요.
- 데이터마트를 주도적으로 설계, 구축하고 운영한 경험이 있으신 분이 필요해요.
- 복잡하거나 반복적인 문제를 데이터모델을 이용하여 단순화, 자동화하여 해결한 경험이 있으신 분이 필요해요.
- SQL 상급, Python 중급 정도의 기술역량이 있으신 분이 필요해요.
- Airflow 개발 및 운영 경험이 있으신 분이면 좋아요.
- 다양한 시각화 도구를 활용하거나, 분석도구를 연동하여 분석 효율을 높인 경험이 있으신 분이면 좋아요.



#### DBA



##### 자격 요건

- Oracle DBA로 3년 이상의 운영 경험.
- 대용량 DB 운영 경험을 가지고 계시고 SQL 튜닝이 가능
- SQL 및 Shell을 이용한 운영 스크립트 개발이 가능
- MySQL DBA 등 다양한 RDB를 경험과 CDC솔루션(OGG, SharePlex) 및 데이터 모델링 등 DA 업무 경험자
- 긍정적인 마인드와 24시간 365일 대고객 서비스를 주도적으로 이끌어갈 수 있는 열정이 있는 분





## [아이엠 에이아이 ImAI]



##### 사용하는 기술 스택

\- Tensorflow, Pytorch, QT, Clickhouse, MongoDB, C++, Python
\- Docker, AWS, Github, Slack, Notion



##### 주요업무

- 실시간 객체검출 모델 구현
- 영상 또는 생체신호 데이터 AI모델 학습/평가/결과 분석
- 인공지능 시스템 환경 구축 및 고도화



##### 자격요건

- 1년 이상의 Python, C++ 기반 개발 경력을 가지신 분
- 데이터 모델링을 통해 다양한 문제를 해결해 보신 분
- 통계학, 빅데이터학, 수학 등 관련 전공자 혹은 이에 준하는 지식을 가지신 분
- 대졸 이상의 학력을 소지하신 분



##### 우대사항

- 관련 분야의 석사 학위를 보유하신 분
- Linux 사용경험을 가지신 분
- Qt 프레임워크를 이용하여 개발 경험을 가진 분
- 대용량/실시간 데이터 처리 아키텍쳐 구축 경험을 가진 분



##### 디버깅 프로세스

- 문제가 발생한 근본 원인(Root cause)를 잘 찾았는가? (5Whys)
- 같은 문제를 겪지 않으려면 어떻게 해야 할 것인가?
- 피할 수 없는 문제라면 어떻게 새롭게 만들 것인가?
- 그리고 사전적 알림을 어떻게 받을 것인가?
- 현재 나온 대안이 최적의 방향인가?





## [옴니버스]



##### 주요업무

- AI 모델을 학습하고 평가하기 위한 백엔드 웹 서비스를 개발하고 운영합니다.
- 여러 종류의 대용량 데이터를 수집하여 적재하기 위한 시스템을 설계하고 구현합니다.
- 데이터의 유실을 방지하고 데이터의 정합성과 신뢰성을 보장할 수 있는 시스템을 설계하고 구현합니다.



##### 자격요건

- 웹 서비스 개발 (python , java , C#) 및 운영 경험이 있으신 분
- 대용량 데이터의 ETL 설계 및 개발, 운영경험이 있으신분
- RDB, NoSQL에 대한 설계 및 운영 경험이 있으신 분
- 다양한 배경을 가진 팀원들과 협업을 위한 원활한 커뮤니케이션이 가능하신 분



##### 우대사항

- AWS/GCP 클라우드 환경에서 서비스 설계 및 구현 경험이 있으신 분
- Container (Docker, Kubernetes) 기반 서비스의 개발 및 배포 경험이 있으신 분
- 데이터 기반의 서비스에 대한 개발 및 상용화 경험이 있으신 분
- Elasticsearch와 같은 검색엔진을 활용하여 개발한 경험이 있으신 분
- 다양한 분야의 팀원과 Sprint 단위의 협업 경험이 있는 분
- AI 기술이 실생활의 문제를 해결하는 제품으로 만들어지기까지의 과정에 기여하고자 하는 분





## [라플라스]



##### 주요업무

- 빅데이터 분석을 위한 데이터 파이프라인 개발
- Airflow, AWS EMR, Glue, RDS, EKS, Kinesis 등 사용
- 데이터 레이크 개발 및 데이터 엔지니어링 시스템 구축
- 전사 데이터 파이프라인 운영
- 3rd Party API를 통한 데이터 통합



##### 자격요건

- 다량의 네트워크 처리가 가능한 빅데이터 분석 웹 애플리케이션 백엔드 설계 역량
- docker, k8s에 대한 이해
- 데이터 엔지니어링 및 데이터 파이프라인에 대한 이해
- 컴퓨터 공학 전공자 혹은 그에 준하는 전공 지식을 보유한 자



##### 우대사항

- 이커머스, 금융 투자 데이터 분석 경험
- VC, Growth hacking에 대한 경험
- 오픈소스 프로젝트 활동 경험
- OLAP 분석 경험
- Kafka 등 데이터 스트리밍 구현 경험
- InfluxDB 등 시계열 DB 관련 경험
- ML, DL 관련 프로젝트 경험
  